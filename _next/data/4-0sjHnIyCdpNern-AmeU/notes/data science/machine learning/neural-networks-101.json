{"pageProps":{"noteKey":["data science","machine learning","neural-networks-101"],"note":{"title":"Neural Networks 101","date":"2022-06-06","content":"\n<p><code>Feedforward neural network</code> consists of two main components - <code>neurons</code> and <code>synapses</code>.</p>\n<p>\n  <img src=\"/_images/neural-networks-1.png\" alt=\"neural network example\">\n</p>\n<p>\n  On this example we see simple neural network with 3 neurons and 5 synapses.\n  There are two layers - inputs and outputs layers. There may be more layers with arbitrary number\n  of neurons. These middle layers are called hidden. But on input and output layers we have same amount of neurons as we have input sources\n  and outputs we want to receive.\n</p>\n<p>The more layers and neurons neural network has, the more advanced and abstract concept it can handle.</p>\n<p>\n  Basic principle of <code>FFNN</code> - send some numbers to the inputs, than neural network propagating these\n  values through it's neurons, which change the values somehow. This is called <code>feedforwarding</code>. And\n  on the output we receive some changed numbers, which in their turn will be an answer.\n</p>\n<p>\n  For the neural network this is only numbers and their respective change. We give these numbers their\n  meaning. For example, we send to the neural network a picture as a bite array and on single output\n  we have a number between 0 and 1. We decide, that this output means presence or absence of some object\n  on the provided image. Initially all outputs of our network may be completely useless. We need to\n  train neural network. Feeding it with some data set and giving a feedback we seek a moment, when\n  it will return proper output. From now on we can consider our neural network trained and can feed it\n  with some new data, which it does not know yet and with high probability will get meaningful results.\n</p>\n<p>\n  <code>neurons</code> are processing unit, which has at least one input and output. It receives some value,\n  changes it with some criteria and returns changed value into output. Neuron has a <code>bias</code>, which\n  works similarly to threshold - when input value is big enough it will be propagated, otherwise will\n  output 0.\n</p>\n<p>\n  <code>synapses</code> are connections between <code>neurons</code>. Each synapse has <code>weight</code>, which is a multiplicator on\n  a value, transferred through this synapse.\n</p>\n<p>\n  <img src=\"/_images/neural-networks-2.png\" alt=\"neural network with weights and biases\">\n</p>\n<p>\n  On the first attempt we can give weights and biases totally random values. And then we need to train\n  neural network in order to get meaningful results. To do that some algorithms used, for example\n  <code>back propagation</code>. It works like that: network is feed with some amount of different data, it\n  responds to it and here we need to tell it the correct result it should have been responded with.\n  Back propagation goes back on neural network, adjusting weights and biases accordingly. This\n  approximates future results.\n</p>\n<p>\n  Important to note, that this learning may improve results to some close point or stop on local\n  optimum and not improve further.\n</p>\n<p>Back propagation is good, when we have rich set of data with certain output.</p>\n<h2>References</h2>\n<ul>\n  <li><a href=\"https://pwy.io/en/posts/learning-to-fly-pt1/\"></a></li>\n  <li><a href=\"https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\">A Comprehensive Guide to Convolutional Neural Networks â€” the ELI5 way</a></li>\n  <li><a href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron\">Multilayer perceptron</a></li>\n  <li><a href=\"https://en.wikipedia.org/wiki/Feedforward_neural_network\">Feedforward neural network</a></li>\n</ul>\n"}},"__N_SSG":true}